{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e244f3aa-fd16-4a61-b69c-88fd48b17ff4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset split into train, val, and test folders!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from sklearn.model_selection import train_test_split\n",
    "import shutil\n",
    "\n",
    "# Define paths\n",
    "base_dir = 'C:\\\\Users\\\\akars\\\\Downloads\\\\Self Driving Car.v2-fixed-large.yolov8\\\\export'\n",
    "images_dir = os.path.join(base_dir, 'images')\n",
    "labels_dir = os.path.join(base_dir, 'labels')\n",
    "\n",
    "# Ratios for splitting\n",
    "train_ratio = 0.7  # 70% for training\n",
    "val_ratio = 0.2    # 20% for validation\n",
    "test_ratio = 0.1   # 10% for testing\n",
    "\n",
    "# Create train, val, and test directories if they don't exist\n",
    "for folder in ['train', 'val', 'test']:\n",
    "    os.makedirs(os.path.join(images_dir, folder), exist_ok=True)\n",
    "    os.makedirs(os.path.join(labels_dir, folder), exist_ok=True)\n",
    "\n",
    "# Get list of image files\n",
    "images = [f for f in os.listdir(images_dir) if f.endswith(('.jpg', '.png'))]\n",
    "\n",
    "# First, split into train+val and test\n",
    "train_val_images, test_images = train_test_split(images, test_size=test_ratio, random_state=42)\n",
    "\n",
    "# Then split train+val into train and val\n",
    "train_images, val_images = train_test_split(train_val_images, test_size=val_ratio/(train_ratio + val_ratio), random_state=42)\n",
    "\n",
    "# Move images and labels to train/val/test folders\n",
    "for img_list, dest in [(train_images, 'train'), (val_images, 'val'), (test_images, 'test')]:\n",
    "    for img in img_list:\n",
    "        shutil.move(os.path.join(images_dir, img), os.path.join(images_dir, dest, img))\n",
    "        label = img.replace('.jpg', '.txt').replace('.png', '.txt')\n",
    "        shutil.move(os.path.join(labels_dir, label), os.path.join(labels_dir, dest, label))\n",
    "\n",
    "print(\"Dataset split into train, val, and test folders!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "891571ae-bd9c-4b07-b1fc-0144bd6c04dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4ae67946-d66f-4ce3-b2a3-67e1a1ec435a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the YOLOv8 model (pre-trained on COCO dataset)\n",
    "model = YOLO('yolov8n.pt')  # Use 'yolov8n.pt' for the smallest, fastest model; adjust to 'yolov8m.pt' or 'yolov8l.pt' for better accuracy\n",
    "\n",
    "# Specify the path to your data.yaml file\n",
    "data_path = 'C:\\\\Users\\\\akars\\\\Downloads\\\\Self Driving Car.v2-fixed-large.yolov8\\\\data.yaml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d35bf18-51ff-4637-9171-c663bd478cdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ultralytics 8.3.78  Python-3.12.0 torch-2.6.0+cpu CPU (11th Gen Intel Core(TM) i5-1135G7 2.40GHz)\n",
      "\u001b[34m\u001b[1mengine\\trainer: \u001b[0mtask=detect, mode=train, model=yolov8n.pt, data=C:\\Users\\akars\\Downloads\\Self Driving Car.v2-fixed-large.yolov8\\data.yaml, epochs=50, time=None, patience=50, batch=8, imgsz=640, save=True, save_period=-1, cache=False, device=cpu, workers=8, project=runs/train, name=exp2, exist_ok=False, pretrained=True, optimizer=Adam, verbose=True, seed=0, deterministic=True, single_cls=False, rect=False, cos_lr=False, close_mosaic=10, resume=False, amp=True, fraction=1.0, profile=False, freeze=None, multi_scale=False, overlap_mask=True, mask_ratio=4, dropout=0.0, val=True, split=val, save_json=False, save_hybrid=False, conf=None, iou=0.7, max_det=300, half=False, dnn=False, plots=True, source=None, vid_stride=1, stream_buffer=False, visualize=False, augment=False, agnostic_nms=False, classes=None, retina_masks=False, embed=None, show=False, save_frames=False, save_txt=False, save_conf=False, save_crop=False, show_labels=True, show_conf=True, show_boxes=True, line_width=None, format=torchscript, keras=False, optimize=False, int8=False, dynamic=False, simplify=True, opset=None, workspace=None, nms=False, lr0=0.001, lrf=0.01, momentum=0.937, weight_decay=0.0005, warmup_epochs=3.0, warmup_momentum=0.8, warmup_bias_lr=0.1, box=7.5, cls=0.5, dfl=1.5, pose=12.0, kobj=1.0, nbs=64, hsv_h=0.015, hsv_s=0.7, hsv_v=0.4, degrees=0.0, translate=0.1, scale=0.5, shear=0.0, perspective=0.0, flipud=0.0, fliplr=0.5, bgr=0.0, mosaic=1.0, mixup=0.0, copy_paste=0.0, copy_paste_mode=flip, auto_augment=randaugment, erasing=0.4, crop_fraction=1.0, cfg=None, tracker=botsort.yaml, save_dir=runs\\train\\exp2\n",
      "Downloading https://ultralytics.com/assets/Arial.ttf to 'C:\\Users\\akars\\AppData\\Roaming\\Ultralytics\\Arial.ttf'...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████| 755k/755k [00:00<00:00, 2.10MB/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overriding model.yaml nc=80 with nc=11\n",
      "\n",
      "                   from  n    params  module                                       arguments                     \n",
      "  0                  -1  1       464  ultralytics.nn.modules.conv.Conv             [3, 16, 3, 2]                 \n",
      "  1                  -1  1      4672  ultralytics.nn.modules.conv.Conv             [16, 32, 3, 2]                \n",
      "  2                  -1  1      7360  ultralytics.nn.modules.block.C2f             [32, 32, 1, True]             \n",
      "  3                  -1  1     18560  ultralytics.nn.modules.conv.Conv             [32, 64, 3, 2]                \n",
      "  4                  -1  2     49664  ultralytics.nn.modules.block.C2f             [64, 64, 2, True]             \n",
      "  5                  -1  1     73984  ultralytics.nn.modules.conv.Conv             [64, 128, 3, 2]               \n",
      "  6                  -1  2    197632  ultralytics.nn.modules.block.C2f             [128, 128, 2, True]           \n",
      "  7                  -1  1    295424  ultralytics.nn.modules.conv.Conv             [128, 256, 3, 2]              \n",
      "  8                  -1  1    460288  ultralytics.nn.modules.block.C2f             [256, 256, 1, True]           \n",
      "  9                  -1  1    164608  ultralytics.nn.modules.block.SPPF            [256, 256, 5]                 \n",
      " 10                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 11             [-1, 6]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 12                  -1  1    148224  ultralytics.nn.modules.block.C2f             [384, 128, 1]                 \n",
      " 13                  -1  1         0  torch.nn.modules.upsampling.Upsample         [None, 2, 'nearest']          \n",
      " 14             [-1, 4]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 15                  -1  1     37248  ultralytics.nn.modules.block.C2f             [192, 64, 1]                  \n",
      " 16                  -1  1     36992  ultralytics.nn.modules.conv.Conv             [64, 64, 3, 2]                \n",
      " 17            [-1, 12]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 18                  -1  1    123648  ultralytics.nn.modules.block.C2f             [192, 128, 1]                 \n",
      " 19                  -1  1    147712  ultralytics.nn.modules.conv.Conv             [128, 128, 3, 2]              \n",
      " 20             [-1, 9]  1         0  ultralytics.nn.modules.conv.Concat           [1]                           \n",
      " 21                  -1  1    493056  ultralytics.nn.modules.block.C2f             [384, 256, 1]                 \n",
      " 22        [15, 18, 21]  1    753457  ultralytics.nn.modules.head.Detect           [11, [64, 128, 256]]          \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model summary: 129 layers, 3,012,993 parameters, 3,012,977 gradients, 8.2 GFLOPs\n",
      "\n",
      "Transferred 319/355 items from pretrained weights\n",
      "Freezing layer 'model.22.dfl.conv.weight'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mScanning C:\\Users\\akars\\Downloads\\Self Driving Car.v2-fixed-large.yolov8\\export\\labels\\train... 20999 images, 24\u001b[0m"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\akars\\Downloads\\Self Driving Car.v2-fixed-large.yolov8\\export\\images\\train\\1478021875081281646_jpg.rf.WunDcvXVoFNqRoFjeErN.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\akars\\Downloads\\Self Driving Car.v2-fixed-large.yolov8\\export\\images\\train\\1478021875081281646_jpg.rf.a03153da0a7da83181bc4f2609cac701.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\akars\\Downloads\\Self Driving Car.v2-fixed-large.yolov8\\export\\images\\train\\1478897760163798179_jpg.rf.0696dced8eeae0b14b5d628a3af59950.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\akars\\Downloads\\Self Driving Car.v2-fixed-large.yolov8\\export\\images\\train\\1478897760163798179_jpg.rf.5O1BAdYA04PwZIMgMC9x.jpg: 1 duplicate labels removed\n",
      "\u001b[34m\u001b[1mtrain: \u001b[0mWARNING  C:\\Users\\akars\\Downloads\\Self Driving Car.v2-fixed-large.yolov8\\export\\images\\train\\1478898145212453716_jpg.rf.8snsxjv39szUe3JobWPO.jpg: 1 duplicate labels removed\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mtrain: \u001b[0mNew cache created: C:\\Users\\akars\\Downloads\\Self Driving Car.v2-fixed-large.yolov8\\export\\labels\\train.cache\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mScanning C:\\Users\\akars\\Downloads\\Self Driving Car.v2-fixed-large.yolov8\\export\\labels\\val... 6001 images, 694 bac\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mval: \u001b[0mNew cache created: C:\\Users\\akars\\Downloads\\Self Driving Car.v2-fixed-large.yolov8\\export\\labels\\val.cache\n",
      "Plotting labels to runs\\train\\exp2\\labels.jpg... \n",
      "\u001b[34m\u001b[1moptimizer:\u001b[0m Adam(lr=0.001, momentum=0.937) with parameter groups 57 weight(decay=0.0), 64 weight(decay=0.0005), 63 bias(decay=0.0)\n",
      "Image sizes 640 train, 640 val\n",
      "Using 0 dataloader workers\n",
      "Logging results to \u001b[1mruns\\train\\exp2\u001b[0m\n",
      "Starting training for 50 epochs...\n",
      "\n",
      "      Epoch    GPU_mem   box_loss   cls_loss   dfl_loss  Instances       Size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "       1/50         0G      1.699      1.537       1.19         83        640:  31%|███       | 812/2625 [40:52<2:33:50"
     ]
    }
   ],
   "source": [
    "# Train the model on CPU\n",
    "results = model.train(\n",
    "    data=data_path,                   # Path to data.yaml\n",
    "    epochs=50,                       # Number of training epochs (adjust based on dataset size)\n",
    "    imgsz=640,                       # Image size (must be divisible by 32, e.g., 640x640)\n",
    "    batch=8,                         # Reduce batch size for CPU (e.g., 8 to avoid memory errors)\n",
    "    project='runs/train',            # Directory to save training results\n",
    "    name='exp',                      # Experiment name\n",
    "    optimizer='Adam',                # Optimizer (default is SGD, but Adam can converge faster)\n",
    "    lr0=0.001,                       # Initial learning rate\n",
    "    patience=50,                     # Stop training if no improvement after 50 epochs\n",
    "    device='cpu'                     # Explicitly use CPU\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5e550273-95e9-4d1b-a5d0-10bad24f641a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the trained model\n",
    "model.save('yolov8n_trained.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52a70574-c98c-4f75-8906-f8e0f3c5438e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Training completed! Model saved as 'yolov8n_trained.pt'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e68bf1e6-1481-43ab-93bb-857b3ed82b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from ultralytics import YOLO\n",
    "\n",
    "# Load the trained model\n",
    "model = YOLO('yolov8n_trained.pt')\n",
    "\n",
    "# Evaluate the model on the validation or test dataset\n",
    "results = model.val(data='C:\\\\Users\\\\akars\\\\Downloads\\\\Self Driving Car.v2-fixed-large.yolov8\\\\data.yaml')\n",
    "\n",
    "# Print accuracy metrics\n",
    "print(f\"mAP50: {results.box.map:.3f}\")\n",
    "print(f\"mAP50-95: {results.box.map50_95:.3f}\")\n",
    "print(f\"Precision: {results.box.precision:.3f}\")\n",
    "print(f\"Recall: {results.box.recall:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
